// src/gemini_interactor.js
// Generated by Codex Omega. Rigor Level: HIGH.
// REQ: Handles all Gemini API communication and history management.
// BIAS_ACTION: Explicit error handling and logging for API interactions.

import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai';
import dotenv from 'dotenv';

dotenv.config(); // REQ: Loads Gemini API key from .env.

const API_KEY = process.env.GEMINI_API_KEY;
// CHECK: API key presence.
if (!API_KEY) {
    console.error("[Gemini Interactor] CRITICAL ERROR: GEMINI_API_KEY not found in .env file. Please create .env and add your key.");
    // Codex Omega: Setup failure. Abort.
    process.exit(1);
}

const genAI = new GoogleGenerativeAI(API_KEY);

// REQ: Configurable generation parameters.
const generationConfig = {
    temperature: 0.6, // Slightly lower for more deterministic tool use generation
    topK: 1,          // As per reference, but can be tuned
    topP: 1,          // As per reference
    maxOutputTokens: 65000, // Increased for potentially complex responses or tool calls
};

// REQ: Standard safety settings.
const safetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
];

export class GeminiInteractor {
    constructor(systemInstructionText) {
        // CHECK: System instruction presence.
        if (!systemInstructionText || typeof systemInstructionText !== 'string' || systemInstructionText.trim() === '') {
            console.error("[Gemini Interactor] CRITICAL ERROR: System instruction text is missing or empty.");
            process.exit(1);
        }
        this.model = genAI.getGenerativeModel({
            model: "gemini-2.5-flash-preview-04-17", // REQ: Use specified model.
            // REQ: System instruction is critical for defining behavior and tool use.
            systemInstruction: {
                // Role for system instruction parts is implicitly 'system' if directly providing parts array
                // or explicitly set role: 'user' if model requires it (gemini-2.5-flash should handle this well)
                parts: [{ text: systemInstructionText }]
            },
            generationConfig,
            safetySettings
        });
        // REQ: Manages chat history.
        this.chatHistory = []; // Format: { role: "user" | "model", parts: [{text: "..."}] }
        console.log('[Gemini Interactor] Instance created and model initialized.');
    }

    async sendMessage(userMessageText) {
        // CHECK: User message validity.
        if (!userMessageText || typeof userMessageText !== 'string' || userMessageText.trim() === '') {
            console.warn("[Gemini Interactor] Attempted to send an empty user message.");
            return "Cannot process an empty message."; // Or throw error
        }

        console.log(`\n[Gemini Interactor] Sending to Gemini: "${userMessageText.substring(0,100)}${userMessageText.length > 100 ? '...' : ''}"`);

        // Add current user message to history *before* sending, as per Gemini SDK's chat model
        // The history sent to `startChat` should not include the absolute latest user message if `sendMessage` takes it as an arg.
        // Let's adjust to always build full history for `startChat`.
        const currentTurnUserMessage = { role: "user", parts: [{ text: userMessageText }] };
        const historyForThisCall = [...this.chatHistory, currentTurnUserMessage];

        try {
            // For ongoing chat, it's often better to manage history explicitly and pass to generateContent
            // or ensure startChat gets the most up-to-date history correctly.
            // The `startChat` method is suitable if we let it manage history internally after init.
            // However, since we add tool responses as "user" turns, managing history externally is more robust.

            const result = await this.model.generateContent({
                contents: historyForThisCall, // Pass the full history including the current user message
                // generationConfig, safetySettings are part of model init
            });

            const response = result.response;
            const responseText = response.text(); // REQ: Extract text response.

            // Log safety ratings and finish reason for diagnostics
            // BIAS_ACTION: Logging this helps diagnose unexpected behavior or content filtering.
            const candidate = response.candidates?.[0];
            if (candidate) {
                console.log(`[Gemini Interactor] Finish Reason: ${candidate.finishReason || 'N/A'}`);
                if (candidate.safetyRatings) {
                    // console.log(`[Gemini Interactor] Safety Ratings: ${JSON.stringify(candidate.safetyRatings)}`);
                    const blocked = candidate.safetyRatings.some(r => r.blocked);
                    if (blocked) {
                         console.warn(`[Gemini Interactor] Response may have been blocked or altered due to safety settings.`);
                         // Codex Omega: Critical if this prevents tool use or valid responses.
                    }
                }
            }
            if (response.promptFeedback) {
                // console.log(`[Gemini Interactor] Prompt Feedback: ${JSON.stringify(response.promptFeedback)}`);
                 if (response.promptFeedback.blockReason) {
                    console.error(`[Gemini Interactor] Prompt was blocked. Reason: ${response.promptFeedback.blockReason}`);
                    // Codex Omega: This is a failure state.
                    return `My ability to respond to your last prompt was blocked. Reason: ${response.promptFeedback.blockReason}. Please rephrase or try a different query.`;
                 }
            }

            // console.log(`[Gemini Interactor] Gemini raw response: "${responseText.substring(0,150)}${responseText.length > 150 ? '...' : ''}"`);

            // Add both user's current message and model's response to persistent history
            this.chatHistory.push(currentTurnUserMessage);
            this.chatHistory.push({ role: "model", parts: [{ text: responseText }] });

            return responseText;

        } catch (error) {
            console.error("[Gemini Interactor] ERROR calling Gemini API:", error.message);
            // Codex Omega: API failure is critical.
            // Provide more detail if available in the error object
            if (error.toString().includes("SAFETY")) {
                 return "My response was blocked due to safety settings. Please try a different prompt.";
            }
            return `Sorry, I encountered an error trying to communicate with the AI model: ${error.message}`;
        }
    }

    /**
     * Adds a tool response to the chat history as a 'user' turn, optionally including image data.
     * This prepares the history for the next call to the Gemini API, allowing the model to see the tool's output.
     * @param {string} toolResponseText - The text content of the tool's response.
     * @param {object | null} imageData - Optional object containing image data: { base64: string, mimeType: string }.
     */
    addToolResponseMessage(toolResponseText, imageData = null) {
        // REQ: Formats tool result and adds to history for next turn.
        // This message will be part of the "user" turn that Gemini sees, providing context about the tool's output.

        const parts = [{ text: `[System notification: Tool Result Received]\n${toolResponseText}` }];

        // Add image data part if provided and valid
        if (imageData && typeof imageData.base64 === 'string' && typeof imageData.mimeType === 'string') {
            parts.push({
                inlineData: {
                    data: imageData.base64,
                    mimeType: imageData.mimeType
                }
            });
            console.log('[Gemini Interactor] Image data added to tool result parts.');
        } else if (imageData !== null) {
             // Log if imageData was provided but wasn't in the expected format
             console.warn('[Gemini Interactor] Invalid image data format provided for tool result.');
        } else {
             console.log('[Gemini Interactor] No image data provided for tool result.');
        }

        // This will be the *start* of the next user message to Gemini, so it acts as context.
        // The main loop will then call sendMessage with *this* as the user input.
        this.chatHistory.push({ role: "user", parts: parts });
        console.log('[Gemini Interactor] Tool result (potentially with image) added to chat history to inform next Gemini turn.');
    }

    addFollowUpMessageForToolResult(baseMessageFromToolResult) {
        // REQ: Send tool result back to Gemini as part of the next turn.
        // This is part of the "user" turn in the conversation history.
        // This message is constructed by main.js after a tool call.
        this.chatHistory.push({ role: "user", parts: [{ text: baseMessageFromToolResult }] });
        console.log('[Gemini Interactor] Tool result processing message added to chat history.');
    }


    getChatHistory() {
        // REQ: For debugging or potential future use.
        return [...this.chatHistory]; // Return a copy
    }
}
